apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: semantic-router
  namespace: vllm-semantic-router-system
  annotations:
    kubernetes.io/ingress.class: nginx
    # Enable compression for JSON payloads
    nginx.ingress.kubernetes.io/enable-cors: "true"
    nginx.ingress.kubernetes.io/cors-allow-methods: "GET, POST, OPTIONS"
    nginx.ingress.kubernetes.io/cors-allow-headers: "DNT,X-CustomHeader,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization"
    nginx.ingress.kubernetes.io/proxy-body-size: "10m"
    nginx.ingress.kubernetes.io/proxy-connect-timeout: "120"
    nginx.ingress.kubernetes.io/proxy-read-timeout: "120"
    nginx.ingress.kubernetes.io/proxy-send-timeout: "120"
    # Required to preserve LLM response formatting (newlines)
    nginx.ingress.kubernetes.io/configuration-snippet: |
      more_clear_headers "Content-Type";
      more_set_headers "Content-Type: $upstream_http_content_type";
spec:
  rules:
  - http:
      paths:
      - path: /v1/chat/completions
        pathType: Exact
        backend:
          service:
            name: semantic-router
            port:
              name: http-gateway
      - path: /v1/models
        pathType: Exact
        backend:
          service:
            name: semantic-router
            port:
              name: http-gateway